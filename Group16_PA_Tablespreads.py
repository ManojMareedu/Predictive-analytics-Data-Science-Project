# -*- coding: utf-8 -*-
"""PA Tablespreads.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U9ubznsQeRmRHKaNwvOtdofv94bMrC4X
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline 
import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os 

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

os.chdir('/content/drive/MyDrive/Datasets/')

"""# Reading the Data which is in .xlsx format."""

df2018 = pd.read_excel("/content/drive/MyDrive/Datasets/IRI_POS_Tablespreads_2018.xlsx")

df2019 = pd.read_excel("/content/drive/MyDrive/Datasets/IRI_POS_Tablespreads_2019.xlsx")

df2020 = pd.read_excel("/content/drive/MyDrive/Datasets/IRI_POS_Tablespreads_2020.xlsx")

df2021 = pd.read_excel("/content/drive/MyDrive/Datasets/IRI_POS_Tablespreads_2021.xlsx")

df2022 = pd.read_excel("/content/drive/MyDrive/Datasets/IRI_POS_Tablespreads_2022.xlsx")

df2022 = df2022.rename(columns={"Product": "Product Description"})

"""# Removing the Duplicates"""

df2018.drop_duplicates()

df2020.drop_duplicates()

df2022.drop_duplicates()

"""# Replacing the Null Values"""

df2018.fillna(0, inplace = True)

df2020.fillna(0, inplace = True)

df2022.fillna(0, inplace = True)

df2018.isnull().sum()

df2020.isnull().sum()

df2022.isnull().sum()

"""# Statistics of each data set"""

df2018[['Dollar Sales No Merch', 'Unit Sales No Merch', 'Price per Unit No Merch']].describe()

df2020[['Dollar Sales No Merch', 'Unit Sales No Merch', 'Price per Unit No Merch']].describe()

df2022[['Dollar Sales No Merch', 'Unit Sales No Merch', 'Price per Unit No Merch']].describe()

"""# Concatinating the 2018, 2020, 2022 Data Frames into single DataFrame"""

df = pd.concat([df2018, df2020, df2022])

df.isnull().sum()

"""# Extracting Year and Brands from Time and Product Description column Respectively

Function for exracting the brand
"""

def brand(row):
  b = ''
  x = list(row['Product Description'].split(' '))
  b= b+x[0]+x[1]
  return b

df['Brands'] = df.apply(lambda row: brand(row), axis =1 )

df['Year'] = pd.to_datetime(df['Time'], format = 'Week Ending %m-%d-%y').dt.year

"""Excluding the Total US region as we have individual region data"""

c = df['Geography'] != 'Total US - Multi Outlet + Conv'

df = df[c]

df

df.columns

"""# Correlation"""

corr_df = df.corr()

fig, ax = plt.subplots(figsize=(15,17)) 
sns.heatmap(corr_df, annot=True, ax=ax)
plt.show()

"""# Dummies for Brands, Regions and Years"""

df_dummy = pd.get_dummies(df, columns=['Geography','Brands','Year'])

l = list(df_dummy.columns)
print(len(l))

print(l)

"""# Hypothesis

H0: These is no significat Difference in unit sales between 2018 and 2020
"""

import pandas as pd
from scipy.stats import ttest_ind

# Load two dataframes


# Extract 'Unit Sales No Merch' columns from each dataframe
unit_sales2018 = df2018['Unit Sales No Merch']
unit_sales2020 = df2020['Unit Sales No Merch']

# Perform two-sample t-test
t_stat, p_value = ttest_ind(unit_sales2018, unit_sales2020, equal_var=False)

# Print results
print('t-statistic 2018-2020: {:.3f}'.format(t_stat))
print('p-value 2018-2020: {:.3f}'.format(p_value))

"""H0: These is no significat Difference in unit sales between 2018 and 2022"""

# Extract 'Unit Sales No Merch' columns from each dataframe
unit_sales2018 = df2018['Unit Sales No Merch']
unit_sales2022 = df2022['Unit Sales No Merch']

# Perform two-sample t-test
t_stat, p_value = ttest_ind(unit_sales2018, unit_sales2022, equal_var=False)

# Print results
print('t-statistic 2018-2022: {:.3f}'.format(t_stat))
print('p-value 2018-2022: {:.3f}'.format(p_value))

"""H0: These is no significat Difference in unit sales between 2020 and 2022"""

unit_sales2020 = df2020['Unit Sales No Merch']
unit_sales2022 = df2022['Unit Sales No Merch']

# Perform two-sample t-test
t_stat, p_value = ttest_ind(unit_sales2020, unit_sales2022, equal_var=False)

# Print results
print('t-statistic 2020-2022: {:.3f}'.format(t_stat))
print('p-value 2020-2022: {:.3f}'.format(p_value))

"""Anova test"""

import statsmodels.api as sm
from statsmodels.formula.api import ols

# create a formula for the ANOVA model
formula = 'Q("Unit Sales No Merch") ~ C(Geography)'

# fit the ANOVA model using ordinary least squares (OLS)
modelols2018 = ols(formula=formula, data=df2018).fit()

# compute ANOVA table
anova_table2018 = sm.stats.anova_lm(modelols2018, typ=2)

# print the ANOVA table
print("   --------------  ANOVA test 2018 -------------  ")
print(anova_table2018)

import statsmodels.api as sm
from statsmodels.formula.api import ols

# create a formula for the ANOVA model
formula = 'Q("Unit Sales No Merch") ~ C(Geography)'

# fit the ANOVA model using ordinary least squares (OLS)
modelols2020 = ols(formula=formula, data=df2020).fit()

# compute ANOVA table
anova_table2020 = sm.stats.anova_lm(modelols2020, typ=2)

# print the ANOVA table
print("   --------------  ANOVA test 2020  -------------  ")
print(anova_table2020)

import statsmodels.api as sm
from statsmodels.formula.api import ols

# create a formula for the ANOVA model
formula = 'Q("Unit Sales No Merch") ~ C(Geography)'

# fit the ANOVA model using ordinary least squares (OLS)
modelols2022 = ols(formula=formula, data=df2022).fit()

# compute ANOVA table
anova_table2022 = sm.stats.anova_lm(modelols2022, typ=2)

# print the ANOVA table
print("   --------------  ANOVA test 2022  -------------  ")
print(anova_table2022)

"""# Building a Linear Regression Model """

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import seaborn as sns

l = list(df_dummy.columns)

r = ['Time',
 'Product Description',
 'UPC 13 digit',
 'Dollar Sales No Merch',
 'Dollar Sales Any Merch',
 'Unit Sales No Merch', 'Unit Sales Any Merch', 'Price per Unit','Price per Volume',
 'Price per Volume No Merch',
 'Price per Volume Any Merch',
 'Base Unit Sales',
 'Volume Sales No Merch', 'Volume Sales Any Merch',
 'Base Dollar Sales',
 'Incremental Units',
 'Incremental Volume',
 'Incremental Dollars']

for i in r:
  l.remove(i)

print(l)

var = l
x= pd.DataFrame(df_dummy[var])
y= pd.DataFrame(df_dummy['Unit Sales No Merch'])

x_train, x_test, y_train, y_test = train_test_split(x,y,test_size= 0.2, random_state=5)

regressor = LinearRegression()
model =regressor.fit(x_train, y_train)

v = pd.DataFrame(model.coef_, index=['Co-efficients']).transpose()
w = pd.DataFrame(x_train.columns, columns = ['Attributes'])

coeff_lrm= pd.concat([w,v], axis=1,)
coeff_lrm

y_pred = model.predict(x_test)

Accuracy=r2_score(y_test,y_pred)*100
print(" Accuracy of the model is %.2f" %Accuracy)

model.score(x_test, y_test)

sns.regplot(x=y_test,y=y_pred,ci=None,scatter_kws={"color": "green"}, line_kws={"color": "red"});
plt.title("Linear Regression Model")
plt.xlabel("Unit Sales No Merch (Actual Value)")
plt.ylabel("Unit Sales No Merch (Predicted Value)")

"""# Lasso"""

from sklearn.linear_model import LassoCV,Lasso

l = list(df_dummy.columns)

r = ['Time',
 'Product Description',
 'UPC 13 digit',
 'Dollar Sales No Merch',
 'Dollar Sales Any Merch',
 'Unit Sales No Merch', 'Unit Sales Any Merch', 'Price per Unit','Price per Volume',
 'Price per Volume No Merch',
 'Price per Volume Any Merch',
 'Base Unit Sales',
 'Volume Sales No Merch', 'Volume Sales Any Merch',
 'Base Dollar Sales',
 'Base Volume Sales',
 'Incremental Units',
 'Incremental Volume',
 'Incremental Dollars']

for i in r:
  l.remove(i)

print(l)

var = l
xlasso= pd.DataFrame(df_dummy[var])
ylasso= pd.DataFrame(df_dummy['Unit Sales No Merch'])

x_trainlasso, x_testlasso, y_trainlasso, y_testlasso = train_test_split(xlasso,ylasso,test_size= 0.2,random_state=5)

# Create a Lasso Regression model with cross-validation
lasso_cv_model = LassoCV(cv=5)

# Fit the model on the training set
lasso_cv_model.fit(x_trainlasso, y_trainlasso)

# Select the optimal value of alpha
alpha_optimal = lasso_cv_model.alpha_

# Create a Lasso Regression model with the optimal value of alpha
lasso_model = Lasso(alpha=alpha_optimal, max_iter=10000)

# Fit the model on the training set
lasso_model.fit(x_trainlasso, y_trainlasso)

# Predict the target variable for the test set
y_pred_lasso = lasso_model.predict(x_testlasso)

# Calculate the R^2 score on the test set
score_lasso = lasso_model.score(x_testlasso, y_testlasso)

# Print the R^2 score and the optimal value of alpha
print("R^2 score for Lasso Regression model:", score_lasso)
print("Optimal value of alpha:", alpha_optimal)

print(alpha_optimal)

lasso_coef = pd.DataFrame(columns=["Feature", "Coefficient"])

for i in range(len(l)):
  print('{} : {}'.format(l[i], lasso_model.coef_[i].transpose()) )
  feature = l[i]
  coefficient = lasso_model.coef_[i]
  lasso_coef = lasso_coef.append({'Feature': feature, 'Coefficient': coefficient}, ignore_index=True)

lasso_coef

sns.regplot(x=y_testlasso,y=y_pred_lasso,ci=None,scatter_kws={"color": "green"}, line_kws={"color": "red"});
plt.title("Lasso model")
plt.xlabel("Unit Sales No Merch (Actual Value)")
plt.ylabel("Unit Sales No Merch (Predicted Value)")

"""# Polynomial Regression"""

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import make_pipeline
from sklearn.metrics import precision_score, recall_score, mean_squared_error

var = ['Price per Unit No Merch', 'Price per Unit Any Merch','ACV Weighted Distribution No Merch','ACV Weighted Distribution Any Merch','Base Volume Sales','Brands_BLUEBONNET','Brands_PRIVATELABEL','Brands_SMARTBALANCE', 'Brands_IMPERIALRFG','Year_2018', 'Year_2019', 'Year_2020', 'Year_2021', 'Year_2022', 'Year_2023']
xpoly= pd.DataFrame(df_dummy[var])
ypoly= pd.DataFrame(df_dummy['Unit Sales No Merch'])

x_trainpoly, x_testpoly, y_trainpoly, y_testpoly = train_test_split(xpoly,ypoly,test_size= 0.2,random_state=5)

poly = make_pipeline(PolynomialFeatures(), LinearRegression())
param = {'polynomialfeatures__degree': [2]}
grid_poly = GridSearchCV(poly, param, cv = 5)
grid_poly.fit(x_trainpoly, y_trainpoly)

grid_poly.best_params_

best_polymodel = grid_poly.best_estimator_

print("Coefficients = ", best_polymodel.named_steps['linearregression'].coef_)
print("\n \n Intercept = ",best_polymodel.named_steps['linearregression'].intercept_)

y_poly_pred = best_polymodel.predict(x_testpoly)

print("R-Square  = {}".format(best_polymodel.score(x_testpoly,y_testpoly)))

print("MSE =",mean_squared_error(y_testpoly, y_poly_pred))

sns.regplot(x=y_testpoly,y=y_poly_pred,ci=None,scatter_kws={"color": "green"}, line_kws={"color": "red"});
plt.title("Polynomial model")
plt.xlabel("Unit Sales No Merch (Actual Value)")
plt.ylabel("Unit Sales No Merch (Predicted Value)")

"""# Testing the model on 2019 Data

"""

df2019_dummy = pd.get_dummies(df, columns=['Geography','Brands','Year'])

y_pred2019 = best_polymodel.predict(df2019_dummy[var])

y_test2019 = df2019_dummy['Unit Sales No Merch']

print("R-Square  = {}".format(best_polymodel.score(df2019_dummy[var],y_test2019)))

sns.regplot(x=y_test2019,y=y_pred2019,ci=None,scatter_kws={"color": "green"}, line_kws={"color": "red"});
plt.title("Polynomial Model Tested on 2019 Dataset")
plt.xlabel("Unit Sales No Merch (Actual Value)")
plt.ylabel("Unit Sales No Merch (Predicted Value)")